{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8275cfcb",
   "metadata": {},
   "source": [
    "# Persisting trained models and scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4422a4",
   "metadata": {},
   "source": [
    "## 1. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6e0e1",
   "metadata": {},
   "source": [
    "The normal work of data analysts generally consists of analyzing them using statistical and machine learning techniques and their subsequent presentation in a report.<br>\n",
    "This is different when the data model is to be used by an application at runtime. In these cases, training a model and using it to predict each instance is often very inefficient. It would be more convenient to train the model, store it, and have it available to be used later by the program or by the part of the program that needs it.<br>\n",
    "Python pickles can be used for this: the model (and the scalers obtained after training) can be stored for later use in order to avoid training the same model for each prediction need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0cb47789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e9d26",
   "metadata": {},
   "source": [
    "## 2. Basic use of Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0335c",
   "metadata": {},
   "source": [
    "<img src=\"files/python_pickle.png\" alt=\"Python Pickle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37bbe41",
   "metadata": {},
   "source": [
    "Image obtained from: https://www.programaenlinea.net/los-pickles-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e38338",
   "metadata": {},
   "source": [
    "Picke es una librería que permite serializar y des-serializar objetos. Dado un objeto el mismo puede almacenarse  en formato binario y en el futuro, puede recuperarse el objeto a partir del archivo binario almacenado. Para más información visitar: https://docs.python.org/3/library/pickle.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41deebff",
   "metadata": {},
   "source": [
    "### 2.1. Saving a simple object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706925bb",
   "metadata": {},
   "source": [
    "#### Object Creation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "863dd78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object:     <__main__.Car object at 0x7fef5e4c9ee0>\n",
      "Attribute: brand= Jeep\n"
     ]
    }
   ],
   "source": [
    "# Definition or a class\n",
    "class Car():\n",
    "    def __init__(self, brand):\n",
    "        self.brand = brand\n",
    "# Creation of an instance of this class:\n",
    "carOne=Car('Jeep')\n",
    "print('Object:    ',carOne)\n",
    "print('Attribute: brand=',carOne.brand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f004710",
   "metadata": {},
   "source": [
    "#### Saving the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "2dda300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='files/object.pkl'\n",
    "pickle.dump(carOne, open(fileName, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c340193",
   "metadata": {},
   "source": [
    "#### Retrieving the object from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "7dc2e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute loaded: brand= Jeep\n"
     ]
    }
   ],
   "source": [
    "otherCar=pickle.load(open(fileName,'rb'))\n",
    "print('Attribute loaded: brand=',otherCar.brand)\n",
    "# Erase file after retrieving object\n",
    "os.remove(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdbbb4",
   "metadata": {},
   "source": [
    "## 3. Pickling a model and a scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d08433a",
   "metadata": {},
   "source": [
    "### 3.1. Training a model: Diabetes Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290c76b",
   "metadata": {},
   "source": [
    "#### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6c501",
   "metadata": {},
   "source": [
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes. The dataset can be downloaded from the site of Kaggle (link: <a href='https://www.kaggle.com/datasets/mathchi/diabetes-data-set'>'click here' </a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425965c",
   "metadata": {},
   "source": [
    "#### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "7e8eb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dataset from sklearn\n",
    "df = pd.read_csv('datasets/diabetes.csv')\n",
    "fields=df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "c57d37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "X_ = df.iloc[:,:len(fields)-1].values\n",
    "y_=df.iloc[:,len(fields)-1]\n",
    "y=np.array(y_)\n",
    "# Scaling data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X_)\n",
    "# Split in Train and Test\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c03467",
   "metadata": {},
   "source": [
    "#### Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "407552e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de las Clasificaciones\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84        97\n",
      "           1       0.80      0.56      0.66        57\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.79      0.74      0.75       154\n",
      "weighted avg       0.79      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the Logistic Regression model\n",
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print('\\nReporte de las Clasificaciones\\n',classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6b024",
   "metadata": {},
   "source": [
    "#### Persistance of Model and Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e4be2",
   "metadata": {},
   "source": [
    "Trained models and scalers can be deployed as pickle files in big applications or complex systems where training models in prediction instances is not allowed because of performance issues. Pickle files contain a summary of the training process in compressed form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "27b50662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model and Scaler\n",
    "fileModel=('files/model.pkl')\n",
    "pickle.dump(model, open(fileModel, 'wb'))\n",
    "fileScaler=('files/scaler.pkl')\n",
    "pickle.dump(sc, open(fileScaler, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0573c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model and scaler from binary files:\n",
    "modelLoaded=pickle.load(open(fileModel,'rb'))\n",
    "scalerLoaded=pickle.load(open(fileScaler,'rb'))\n",
    "# Erase files after retrieving objects\n",
    "os.remove(fileModel)\n",
    "os.remove(fileScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612b9f5",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a1d56",
   "metadata": {},
   "source": [
    "In this step we use information loaded from pickle files in order to predict diabetes diagnoses of some random rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "94ef7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select some random rows from the Dataset\n",
    "nb_of_rows=5\n",
    "X_n=[]\n",
    "random_rows=[]\n",
    "for i in range(nb_of_rows):\n",
    "    random_num=random.randint(0,df.shape[0])\n",
    "    X_n.append(list(X_[random_num]))\n",
    "    random_rows.append(random_num)\n",
    "X_New=np.array(X_n)\n",
    "X_New_Norm=scalerLoaded.fit_transform(X_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "97cc9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 0 1 0]  - Real: [1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Prediction:\n",
    "y_pred=modelLoaded.predict(X_New_Norm)\n",
    "y_real=[]\n",
    "for i in range(nb_of_rows):\n",
    "    y_real.append(y_[random_rows[i]])\n",
    "print('Predicted: ',y_pred,' - Real:',np.array(y_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a8b0c0",
   "metadata": {},
   "source": [
    "## 4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ccf291",
   "metadata": {},
   "source": [
    "The Pickle library is a great tool for persisting objects present in memory, so that they can be used in another instance.\n",
    "It is also convenient when more than one prediction must be made after a learning. In this case, using the models stored in pickle avoids unnecessarily repeating the training of the models, making the systems more performant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
